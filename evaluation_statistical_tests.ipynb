{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BART 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrector is_factual: 0.42 (baseline diff: 0.0)\n",
      "corrector is_factual baseline diff mcnemar p-value: 1.0\n",
      "corrector is_factual baseline diff wilcoxon p-value: 1.0\n",
      "corrector has_extrinsic_and_fully_factual: 0.45 (baseline diff: 0.010000000000000009)\n",
      "corrector has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 1.0\n",
      "corrector has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 0.7054569861112734\n",
      "\n",
      "pinocchio is_factual: 0.43 (baseline diff: 0.010000000000000009)\n",
      "pinocchio is_factual baseline diff mcnemar p-value: 1.0\n",
      "pinocchio is_factual baseline diff wilcoxon p-value: 0.5637028616507731\n",
      "pinocchio has_extrinsic_and_fully_factual: 0.43 (baseline diff: -0.010000000000000009)\n",
      "pinocchio has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 1.0\n",
      "pinocchio has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 0.5637028616507731\n",
      "\n",
      "rl-fact is_factual: 0.55 (baseline diff: 0.13000000000000006)\n",
      "rl-fact is_factual baseline diff mcnemar p-value: 0.004425048828125\n",
      "rl-fact is_factual baseline diff wilcoxon p-value: 0.0028599382084640934\n",
      "rl-fact has_extrinsic_and_fully_factual: 0.39 (baseline diff: -0.04999999999999999)\n",
      "rl-fact has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 0.359283447265625\n",
      "rl-fact has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 0.25134910881022265\n",
      "\n",
      "gef_classifier is_factual: 0.53 (baseline diff: 0.11000000000000004)\n",
      "gef_classifier is_factual baseline diff mcnemar p-value: 0.00341796875\n",
      "gef_classifier is_factual baseline diff wilcoxon p-value: 0.0022819372533154484\n",
      "gef_classifier has_extrinsic_and_fully_factual: 0.44 (baseline diff: 0.0)\n",
      "gef_classifier has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 1.0\n",
      "gef_classifier has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 1.0\n",
      "\n",
      "gef_oracle is_factual: 0.67 (baseline diff: 0.25000000000000006)\n",
      "gef_oracle is_factual baseline diff mcnemar p-value: 5.960464477539063e-08\n",
      "gef_oracle is_factual baseline diff wilcoxon p-value: 5.733031437583867e-07\n",
      "gef_oracle has_extrinsic_and_fully_factual: 0.63 (baseline diff: 0.19)\n",
      "gef_oracle has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 3.814697265625e-06\n",
      "gef_oracle has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 1.3071845366763019e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/factual-beam-search/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n",
      "/usr/local/anaconda3/envs/factual-beam-search/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n",
      "/usr/local/anaconda3/envs/factual-beam-search/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n",
      "/usr/local/anaconda3/envs/factual-beam-search/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "with open(\"results/evaluation/bart-test-extrinsic-100-summaries.json\", \"r\") as f:\n",
    "    json_sums = json.load(f)\n",
    "df = pd.DataFrame(json_sums.values(), index=list(json_sums.keys()))\n",
    "\n",
    "\n",
    "def get_baseline_diff(df, model, metric):\n",
    "    return pd.crosstab(index=df[f\"baseline-bart_{metric}\"], columns=df[f\"{model}_{metric}\"])\n",
    "\n",
    "for model in [\"corrector\", \"pinocchio\", \"rl-fact\", \"gef_classifier\", \"gef_oracle\"]:\n",
    "\n",
    "    for metric in [\"is_factual\", \"has_extrinsic_and_fully_factual\"]:\n",
    "        diff_metric = get_baseline_diff(df, model, metric)\n",
    "        baseline_mean = df[f\"baseline-bart_{metric}\"].mean()\n",
    "        model_mean = df[f\"{model}_{metric}\"].mean()\n",
    "        print(f\"{model} {metric}: {model_mean} (baseline diff: {model_mean - baseline_mean})\")\n",
    "        print(f\"{model} {metric} baseline diff mcnemar p-value: {mcnemar(diff_metric).pvalue}\")\n",
    "        wilcoxon_p = wilcoxon(\n",
    "            df[f\"baseline-bart_{metric}\"].astype(int), \n",
    "            df[f\"{model}_{metric}\"].astype(int)\n",
    "        ).pvalue\n",
    "        print(f\"{model} {metric} baseline diff wilcoxon p-value: {wilcoxon_p}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BART 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrector is_factual: 0.44 (baseline diff: 0.0)\n",
      "corrector is_factual baseline diff mcnemar p-value: 1.0\n",
      "corrector is_factual baseline diff wilcoxon p-value: 1.0\n",
      "corrector has_extrinsic_and_fully_factual: 0.464 (baseline diff: 0.0)\n",
      "corrector has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 1.0\n",
      "corrector has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 1.0\n",
      "\n",
      "pinocchio is_factual: 0.448 (baseline diff: 0.008000000000000007)\n",
      "pinocchio is_factual baseline diff mcnemar p-value: 1.0\n",
      "pinocchio is_factual baseline diff wilcoxon p-value: 0.5637028616507731\n",
      "pinocchio has_extrinsic_and_fully_factual: 0.44 (baseline diff: -0.02400000000000002)\n",
      "pinocchio has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 0.375\n",
      "pinocchio has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 0.17971249487899976\n",
      "\n",
      "rl-fact is_factual: 0.592 (baseline diff: 0.15199999999999997)\n",
      "rl-fact is_factual baseline diff mcnemar p-value: 0.00015652179718017578\n",
      "rl-fact is_factual baseline diff wilcoxon p-value: 0.00014469608785023995\n",
      "rl-fact has_extrinsic_and_fully_factual: 0.4 (baseline diff: -0.064)\n",
      "rl-fact has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 0.15158963203430176\n",
      "rl-fact has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 0.10247043485974937\n",
      "\n",
      "gef_classifier is_factual: 0.536 (baseline diff: 0.09600000000000003)\n",
      "gef_classifier is_factual baseline diff mcnemar p-value: 0.004180908203125\n",
      "gef_classifier is_factual baseline diff wilcoxon p-value: 0.0026997960632601866\n",
      "gef_classifier has_extrinsic_and_fully_factual: 0.456 (baseline diff: -0.008000000000000007)\n",
      "gef_classifier has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 1.0\n",
      "gef_classifier has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 0.7962534147376392\n",
      "\n",
      "gef_oracle is_factual: 0.648 (baseline diff: 0.20800000000000002)\n",
      "gef_oracle is_factual baseline diff mcnemar p-value: 2.9802322387695312e-08\n",
      "gef_oracle is_factual baseline diff wilcoxon p-value: 3.414173577297533e-07\n",
      "gef_oracle has_extrinsic_and_fully_factual: 0.624 (baseline diff: 0.15999999999999998)\n",
      "gef_oracle has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 1.9073486328125e-06\n",
      "gef_oracle has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 7.74421643104407e-06\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/factual-beam-search/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n",
      "/usr/local/anaconda3/envs/factual-beam-search/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n",
      "/usr/local/anaconda3/envs/factual-beam-search/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n",
      "/usr/local/anaconda3/envs/factual-beam-search/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "with open(\"results/evaluation/bart-test-extrinsic-125-summaries.json\", \"r\") as f:\n",
    "    json_sums = json.load(f)\n",
    "df = pd.DataFrame(json_sums.values(), index=list(json_sums.keys()))\n",
    "\n",
    "\n",
    "def get_baseline_diff(df, model, metric):\n",
    "    return pd.crosstab(index=df[f\"baseline-bart_{metric}\"], columns=df[f\"{model}_{metric}\"])\n",
    "\n",
    "for model in [\"corrector\", \"pinocchio\", \"rl-fact\", \"gef_classifier\", \"gef_oracle\"]:\n",
    "\n",
    "    for metric in [\"is_factual\", \"has_extrinsic_and_fully_factual\"]:\n",
    "        diff_metric = get_baseline_diff(df, model, metric)\n",
    "        baseline_mean = df[f\"baseline-bart_{metric}\"].mean()\n",
    "        model_mean = df[f\"{model}_{metric}\"].mean()\n",
    "        print(f\"{model} {metric}: {model_mean} (baseline diff: {model_mean - baseline_mean})\")\n",
    "        print(f\"{model} {metric} baseline diff mcnemar p-value: {mcnemar(diff_metric).pvalue}\")\n",
    "        wilcoxon_p = wilcoxon(\n",
    "            df[f\"baseline-bart_{metric}\"].astype(int), \n",
    "            df[f\"{model}_{metric}\"].astype(int)\n",
    "        ).pvalue\n",
    "        print(f\"{model} {metric} baseline diff wilcoxon p-value: {wilcoxon_p}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gef_classifier is_factual: 0.65 (baseline diff: 0.07000000000000006)\n",
      "gef_classifier is_factual baseline diff mcnemar p-value: 0.11846923828124999\n",
      "gef_classifier is_factual baseline diff wilcoxon p-value: 0.07070114486598297\n",
      "gef_classifier has_extrinsic_and_fully_factual: 0.54 (baseline diff: -0.06999999999999995)\n",
      "gef_classifier has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 0.18924713134765625\n",
      "gef_classifier has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 0.12663045794761718\n",
      "\n",
      "gef_oracle is_factual: 0.79 (baseline diff: 0.21000000000000008)\n",
      "gef_oracle is_factual baseline diff mcnemar p-value: 9.5367431640625e-07\n",
      "gef_oracle is_factual baseline diff wilcoxon p-value: 4.592833711753968e-06\n",
      "gef_oracle has_extrinsic_and_fully_factual: 0.74 (baseline diff: 0.13)\n",
      "gef_oracle has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 0.002349853515625\n",
      "gef_oracle has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 0.0016162222150599857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "with open(\"results/evaluation/pegasus-test-extrinsic-100-summaries.json\", \"r\") as f:\n",
    "    json_sums = json.load(f)\n",
    "df = pd.DataFrame(json_sums.values(), index=list(json_sums.keys()))\n",
    "\n",
    "\n",
    "def get_baseline_diff(df, model, metric):\n",
    "    return pd.crosstab(index=df[f\"baseline-pegasus_{metric}\"], columns=df[f\"{model}_{metric}\"])\n",
    "\n",
    "for model in [\"gef_classifier\", \"gef_oracle\"]:\n",
    "\n",
    "    for metric in [\"is_factual\", \"has_extrinsic_and_fully_factual\"]:\n",
    "        diff_metric = get_baseline_diff(df, model, metric)\n",
    "        baseline_mean = df[f\"baseline-pegasus_{metric}\"].mean()\n",
    "        model_mean = df[f\"{model}_{metric}\"].mean()\n",
    "        print(f\"{model} {metric}: {model_mean} (baseline diff: {model_mean - baseline_mean})\")\n",
    "        print(f\"{model} {metric} baseline diff mcnemar p-value: {mcnemar(diff_metric).pvalue}\")\n",
    "        wilcoxon_p = wilcoxon(\n",
    "            df[f\"baseline-pegasus_{metric}\"].astype(int), \n",
    "            df[f\"{model}_{metric}\"].astype(int)\n",
    "        ).pvalue\n",
    "        print(f\"{model} {metric} baseline diff wilcoxon p-value: {wilcoxon_p}\")\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f3fe5eacab954956417c9014984aac9d559687fff881692b0d4e46fa0e895bd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('factual-beam-search')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
