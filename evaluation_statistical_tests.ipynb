{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrector is_factual: 0.42 (baseline diff: 0.0)\n",
      "corrector is_factual baseline diff mcnemar p-value: 1.0\n",
      "corrector is_factual baseline diff wilcoxon p-value: 1.0\n",
      "corrector has_extrinsic_and_fully_factual: 0.45 (baseline diff: 0.010000000000000009)\n",
      "corrector has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 1.0\n",
      "corrector has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 0.7054569861112734\n",
      "\n",
      "pinocchio is_factual: 0.43 (baseline diff: 0.010000000000000009)\n",
      "pinocchio is_factual baseline diff mcnemar p-value: 1.0\n",
      "pinocchio is_factual baseline diff wilcoxon p-value: 0.5637028616507731\n",
      "pinocchio has_extrinsic_and_fully_factual: 0.43 (baseline diff: -0.010000000000000009)\n",
      "pinocchio has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 1.0\n",
      "pinocchio has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 0.5637028616507731\n",
      "\n",
      "meng-rl is_factual: 0.55 (baseline diff: 0.13000000000000006)\n",
      "meng-rl is_factual baseline diff mcnemar p-value: 0.004425048828125\n",
      "meng-rl is_factual baseline diff wilcoxon p-value: 0.0028599382084640934\n",
      "meng-rl has_extrinsic_and_fully_factual: 0.39 (baseline diff: -0.04999999999999999)\n",
      "meng-rl has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 0.359283447265625\n",
      "meng-rl has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 0.25134910881022265\n",
      "\n",
      "fbs_classifier is_factual: 0.52 (baseline diff: 0.10000000000000003)\n",
      "fbs_classifier is_factual baseline diff mcnemar p-value: 0.012939453125\n",
      "fbs_classifier is_factual baseline diff wilcoxon p-value: 0.007526315166457887\n",
      "fbs_classifier has_extrinsic_and_fully_factual: 0.47 (baseline diff: 0.02999999999999997)\n",
      "fbs_classifier has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 0.548828125\n",
      "fbs_classifier has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 0.36571229628151325\n",
      "\n",
      "fbs_oracle is_factual: 0.65 (baseline diff: 0.23000000000000004)\n",
      "fbs_oracle is_factual baseline diff mcnemar p-value: 1.5497207641601562e-06\n",
      "fbs_oracle is_factual baseline diff wilcoxon p-value: 4.2249094050057074e-06\n",
      "fbs_oracle has_extrinsic_and_fully_factual: 0.62 (baseline diff: 0.18)\n",
      "fbs_oracle has_extrinsic_and_fully_factual baseline diff mcnemar p-value: 4.00543212890625e-05\n",
      "fbs_oracle has_extrinsic_and_fully_factual baseline diff wilcoxon p-value: 5.699411623331837e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/factual-beam-search/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n",
      "/usr/local/anaconda3/envs/factual-beam-search/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n",
      "/usr/local/anaconda3/envs/factual-beam-search/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n",
      "/usr/local/anaconda3/envs/factual-beam-search/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "with open(\"results/evaluation/bart-test-extrinsic-100-summaries.json\", \"r\") as f:\n",
    "    json_sums = json.load(f)\n",
    "df = pd.DataFrame(json_sums.values(), index=list(json_sums.keys()))\n",
    "\n",
    "\n",
    "def get_baseline_diff(df, model, metric):\n",
    "    return pd.crosstab(index=df[f\"baseline-bart_{metric}\"], columns=df[f\"{model}_{metric}\"])\n",
    "\n",
    "for model in [\"corrector\", \"pinocchio\", \"meng-rl\", \"fbs_classifier\", \"fbs_oracle\"]:\n",
    "\n",
    "    for metric in [\"is_factual\", \"has_extrinsic_and_fully_factual\"]:\n",
    "        diff_metric = get_baseline_diff(df, model, metric)\n",
    "        baseline_mean = df[f\"baseline-bart_{metric}\"].mean()\n",
    "        model_mean = df[f\"{model}_{metric}\"].mean()\n",
    "        print(f\"{model} {metric}: {model_mean} (baseline diff: {model_mean - baseline_mean})\")\n",
    "        print(f\"{model} {metric} baseline diff mcnemar p-value: {mcnemar(diff_metric).pvalue}\")\n",
    "        wilcoxon_p = wilcoxon(\n",
    "            df[f\"baseline-bart_{metric}\"].astype(int), \n",
    "            df[f\"{model}_{metric}\"].astype(int)\n",
    "        ).pvalue\n",
    "        print(f\"{model} {metric} baseline diff wilcoxon p-value: {wilcoxon_p}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbs_classifier is_factual: 0.5827338129496403 (baseline diff: 0.1007194244604317)\n",
      "fbs_classifier is_factual baseline diff p-value: 0.001312255859375\n",
      "fbs_classifier has_extrinsic_and_fully_factual: 0.5035971223021583 (baseline diff: 0.007194244604316502)\n",
      "fbs_classifier has_extrinsic_and_fully_factual baseline diff p-value: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "with open(\"results/evaluation/bart-extrinsic-fully-annotated-139-summaries.json\", \"r\") as f:\n",
    "    json_sums = json.load(f)\n",
    "df = pd.DataFrame(json_sums.values(), index=list(json_sums.keys()))\n",
    "\n",
    "\n",
    "def get_baseline_diff(df, model, metric):\n",
    "    return pd.crosstab(index=df[f\"baseline-bart_{metric}\"], columns=df[f\"{model}_{metric}\"])\n",
    "\n",
    "for model in [\"fbs_classifier\"]:\n",
    "\n",
    "    for metric in [\"is_factual\", \"has_extrinsic_and_fully_factual\"]:\n",
    "        diff_metric = get_baseline_diff(df, model, metric)\n",
    "        baseline_mean = df[f\"baseline-bart_{metric}\"].mean()\n",
    "        model_mean = df[f\"{model}_{metric}\"].mean()\n",
    "        print(f\"{model} {metric}: {model_mean} (baseline diff: {model_mean - baseline_mean})\")\n",
    "        print(f\"{model} {metric} baseline diff p-value: {mcnemar(diff_metric).pvalue}\")\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f3fe5eacab954956417c9014984aac9d559687fff881692b0d4e46fa0e895bd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('factual-beam-search')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
